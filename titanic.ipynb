{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "TITANIC_PATH = os.path.join(\"datasets\", \"titanic\")\n",
    "def load_titanic_data(filename, titanic_path=TITANIC_PATH):\n",
    "    csv_path = os.path.join(titanic_path, filename)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytywanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_titanic_data(\"train.csv\")\n",
    "test_data = load_titanic_data(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzanie otrzymanych danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.616162\n",
       "1    0.383838\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Survived'].value_counts()/(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(['Survived'], axis = 1)\n",
    "y_train = train_data['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass  Sex   \n",
      "1       female    35.0\n",
      "        male      40.0\n",
      "2       female    28.0\n",
      "        male      30.0\n",
      "3       female    21.5\n",
      "        male      25.0\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.groupby(['Pclass', 'Sex']).median()['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Age'] = train_data.groupby(['Pclass'])['Age'].apply(lambda x : x.fillna(x.mean()))\n",
    "test_data['Age'] = test_data.groupby(['Pclass'])['Age'].apply(lambda x : x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347082      7\n",
       "CA. 2343    7\n",
       "1601        7\n",
       "3101295     6\n",
       "CA 2144     6\n",
       "           ..\n",
       "9234        1\n",
       "19988       1\n",
       "2693        1\n",
       "PC 17612    1\n",
       "370376      1\n",
       "Name: Ticket, Length: 681, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Ticket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        (\"select_numeric\", DataFrameSelector([\"Age\",\"SibSp\",\"Parch\",\"Fare\"])),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                        index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"select_cat\", DataFrameSelector([\"Pclass\",\"Sex\",\"Embarked\",\"Ticket\"])),\n",
    "        (\"imputer\", MostFrequentImputer()),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False, handle_unknown = 'ignore')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.        ,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [38.        ,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [26.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [25.14061972,  1.        ,  2.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [26.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [32.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testowanie modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 1, 'classifier__solver': 'sag'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_log = Pipeline([\n",
    "  ('preprocessing', preprocess_pipeline), \n",
    "  ('scaler', StandardScaler()),\n",
    "  ('classifier', LogisticRegression(C=1, solver='newton-cg', max_iter = 5000))\n",
    "])\n",
    "\n",
    "\n",
    "param_grid_log = {\n",
    "  'classifier__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "  'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "log_clf = GridSearchCV(pipe_log, param_grid_log, cv=kfold)\n",
    "\n",
    "log_clf.fit(X_train, y_train)\n",
    "log_clf.best_params_\n",
    "#{'classifier__C': 1, 'classifier__solver': 'sag'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = log_clf.predict(test_data)\n",
    "passenger_id = test_data['PassengerId'].values\n",
    "res = pd.DataFrame({'PassengerId':passenger_id,'Survived':pred})\n",
    "res.to_csv('predictions/pred_log_clf.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1, 'classifier__gamma': 1e-25}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lin = Pipeline([\n",
    "  ('preprocessing', preprocess_pipeline), \n",
    "  ('scaler', StandardScaler()),\n",
    "  ('classifier', SVC(kernel = 'linear'))\n",
    "])\n",
    "\n",
    "param_grid_lin = {\n",
    "  'classifier__C': np.logspace(-8, 2, 11),\n",
    "  'classifier__gamma': np.logspace(-25, -15, 11)\n",
    "}\n",
    "\n",
    "lin_clf = GridSearchCV(pipe_lin, param_grid_lin, cv=kfold)\n",
    "\n",
    "lin_clf.fit(X_train, y_train)\n",
    "lin_clf.best_params_\n",
    "#{'classifier__C': 0.1, 'classifier__gamma': 1e-25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lin_clf.predict(test_data)\n",
    "passenger_id = test_data['PassengerId'].values\n",
    "res = pd.DataFrame({'PassengerId':passenger_id,'Survived':pred})\n",
    "res.to_csv('predictions/pred_lin_clf.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 100.0, 'classifier__gamma': 0.0001}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rbf = Pipeline([\n",
    "  ('preprocessing', preprocess_pipeline), \n",
    "  ('scaler', StandardScaler()),\n",
    "  ('classifier', SVC(kernel = 'rbf')),\n",
    "])\n",
    "\n",
    "param_grid_rbf = {\n",
    "  'classifier__C': np.logspace(-5, 5, 11),\n",
    "  'classifier__gamma': np.logspace(-5, 5, 11),\n",
    "}\n",
    "\n",
    "rbf_clf = GridSearchCV(pipe_rbf, param_grid_rbf, cv=kfold)\n",
    "\n",
    "rbf_clf.fit(X_train, y_train)\n",
    "rbf_clf.best_params_\n",
    "#{'classifier__C': 100.0, 'classifier__gamma': 0.0001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rbf_clf.predict(test_data)\n",
    "passenger_id = test_data['PassengerId'].values\n",
    "res = pd.DataFrame({'PassengerId':passenger_id,'Survived':pred})\n",
    "res.to_csv('predictions/pred_rbf_clf.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 100,\n",
       " 'classifier__coef0': 1,\n",
       " 'classifier__degree': 2,\n",
       " 'classifier__gamma': 0.01}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_poly = Pipeline([\n",
    "  ('preprocessing', preprocess_pipeline), \n",
    "  ('scaler', StandardScaler()),\n",
    "  ('classifier', SVC(kernel = 'poly')),\n",
    "])\n",
    "\n",
    "param_grid_poly = {\n",
    "  'classifier__gamma': [0.001, 0.01, 0.1, 1],\n",
    "  'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100,1000, 10000],\n",
    "  'classifier__degree': [1,2,3,4],\n",
    "  'classifier__coef0': [0, 1]\n",
    "}\n",
    "\n",
    "poly_clf = GridSearchCV(pipe_poly, param_grid_poly, cv=kfold, n_jobs= 4)\n",
    "\n",
    "poly_clf.fit(X_train, y_train)\n",
    "poly_clf.best_params_\n",
    "#{'classifier__C': 100,\n",
    "# 'classifier__coef0': 1,\n",
    "# 'classifier__degree': 2,\n",
    "# 'classifier__gamma': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = poly_clf.predict(test_data)\n",
    "passenger_id = test_data['PassengerId'].values\n",
    "res = pd.DataFrame({'PassengerId':passenger_id,'Survived':pred})\n",
    "res.to_csv('predictions/pred_poly_clf.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_forest = Pipeline([\n",
    "  ('preprocessing', preprocess_pipeline), \n",
    "  ('scaler', StandardScaler()),\n",
    "  ('classifier', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "param_grid_forest = {\n",
    "  'classifier__n_estimators': [100, 200, 300, 400], \n",
    "  'classifier__max_depth': [4, 8, 12, 16, 20],\n",
    "  'classifier__max_features': [2, 4, 6, 8, 10]\n",
    "}\n",
    "\n",
    "rf_clf = GridSearchCV(pipe_forest, param_grid_forest, cv=kfold, n_jobs= 4)\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf_clf.predict(test_data)\n",
    "passenger_id = test_data['PassengerId'].values\n",
    "res = pd.DataFrame({'PassengerId':passenger_id,'Survived':pred})\n",
    "res.to_csv('predictions/pred_rf_clf.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50b6c996a8e76fc6c97726ff3b73d1a4f9ab4e411887ecf5062ac1c2e0dec53f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
